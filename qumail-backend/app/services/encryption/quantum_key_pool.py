"""
Quantum Key Pool Manager
Manages a common pool of quantum keys generated by KME1 and consumed by KME2
"""
import asyncio
import logging
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_
from sqlalchemy.orm import selectinload

logger = logging.getLogger(__name__)

class QuantumKeyPool:
    """
    Manages a pool of quantum keys:
    - KME1 generates keys and adds to pool
    - KME2 retrieves keys from pool for encryption/decryption
    - Ensures keys are used only once (OTP principle)
    - Tracks key lifecycle and usage
    """
    
    def __init__(self):
        self.pool = {}  # In-memory cache: key_id -> key_data
        self.key_metadata = {}  # key_id -> metadata
        self.used_keys = set()  # Track used key IDs
        self.lock = asyncio.Lock()
        self.min_pool_size = 100  # Minimum keys to maintain
        self.max_pool_size = 1000  # Maximum keys to store
        
    async def initialize_pool(self, kme_service):
        """Initialize the key pool with quantum keys from KME1"""
        try:
            logger.info("Initializing quantum key pool...")
            
            # Generate initial batch of keys from KME1
            initial_keys = await self._generate_keys_from_kme1(
                kme_service, 
                count=self.min_pool_size
            )
            
            async with self.lock:
                for key_data in initial_keys:
                    key_id = key_data['key_id']
                    self.pool[key_id] = key_data['key_bytes']
                    self.key_metadata[key_id] = {
                        'generated_at': datetime.utcnow(),
                        'source': 'KME1',
                        'size': len(key_data['key_bytes']),
                        'entropy': key_data.get('entropy', 0.0),
                        'status': 'available',
                        'algorithm': key_data.get('algorithm', 'QUANTUM_OTP')
                    }
            
            logger.info(f"Quantum key pool initialized with {len(self.pool)} keys")
            
            # Start background task to maintain pool
            asyncio.create_task(self._maintain_pool(kme_service))
            
        except Exception as e:
            logger.error(f"Failed to initialize quantum key pool: {e}")
            raise
    
    async def _generate_keys_from_kme1(
        self, 
        kme_service, 
        count: int = 10
    ) -> List[Dict[str, Any]]:
        """Generate quantum keys using KME1"""
        try:
            from .real_qkd_client import real_kme1_client
            
            if not real_kme1_client:
                raise Exception("KME1 client not available")
            
            keys = []
            available_key_files = real_kme1_client.get_available_quantum_keys()
            
            if not available_key_files:
                raise Exception("No quantum key files available")
            
            # Generate keys from quantum key files
            for i in range(min(count, len(available_key_files))):
                key_file = available_key_files[i % len(available_key_files)]
                quantum_data = real_kme1_client.load_quantum_key(key_file)
                
                # Split quantum data into multiple keys
                key_size = 256  # 256 bytes per key
                offset = (i * key_size) % (len(quantum_data) - key_size)
                
                if offset + key_size <= len(quantum_data):
                    key_bytes = quantum_data[offset:offset + key_size]
                    entropy = real_kme1_client.get_quantum_entropy(key_bytes)
                    
                    key_id = str(uuid.uuid4())
                    
                    keys.append({
                        'key_id': key_id,
                        'key_bytes': key_bytes,
                        'entropy': entropy,
                        'source_file': key_file,
                        'algorithm': 'QUANTUM_OTP'
                    })
            
            logger.info(f"Generated {len(keys)} quantum keys from KME1")
            return keys
            
        except Exception as e:
            logger.error(f"Error generating keys from KME1: {e}")
            raise
    
    async def get_key_for_encryption(
        self, 
        size: int = 256,
        algorithm: str = 'QUANTUM_OTP'
    ) -> Tuple[str, bytes]:
        """
        Get a quantum key from the pool for encryption
        Returns: (key_id, key_bytes)
        """
        async with self.lock:
            # Find suitable key
            for key_id, key_bytes in self.pool.items():
                if key_id not in self.used_keys:
                    metadata = self.key_metadata.get(key_id, {})
                    
                    # Check if key meets requirements
                    if (len(key_bytes) >= size and 
                        metadata.get('status') == 'available' and
                        metadata.get('algorithm') == algorithm):
                        
                        # Mark as in-use
                        metadata['status'] = 'in_use'
                        metadata['used_at'] = datetime.utcnow()
                        self.key_metadata[key_id] = metadata
                        
                        # Extract required size
                        key_data = key_bytes[:size]
                        
                        logger.info(f"Retrieved key {key_id} from pool for encryption")
                        return key_id, key_data
            
            # No suitable key found
            raise Exception(f"No available quantum key of size {size} in pool")
    
    async def get_key_for_decryption(self, key_id: str) -> Optional[bytes]:
        """
        Get a quantum key from the pool for decryption using key_id
        Returns: key_bytes or None
        """
        async with self.lock:
            if key_id in self.pool:
                key_bytes = self.pool[key_id]
                metadata = self.key_metadata.get(key_id, {})
                
                logger.info(f"Retrieved key {key_id} from pool for decryption")
                return key_bytes
            else:
                logger.warning(f"Key {key_id} not found in pool")
                return None
    
    async def mark_key_consumed(self, key_id: str):
        """Mark a key as consumed (used) - OTP principle"""
        async with self.lock:
            if key_id in self.pool:
                # Remove from pool
                del self.pool[key_id]
                
                # Update metadata
                if key_id in self.key_metadata:
                    self.key_metadata[key_id]['status'] = 'consumed'
                    self.key_metadata[key_id]['consumed_at'] = datetime.utcnow()
                
                # Add to used keys
                self.used_keys.add(key_id)
                
                logger.info(f"Key {key_id} marked as consumed and removed from pool")
    
    async def get_pool_status(self) -> Dict[str, Any]:
        """Get current status of the quantum key pool"""
        async with self.lock:
            available_keys = sum(
                1 for kid, meta in self.key_metadata.items() 
                if meta.get('status') == 'available' and kid in self.pool
            )
            
            in_use_keys = sum(
                1 for meta in self.key_metadata.values() 
                if meta.get('status') == 'in_use'
            )
            
            total_entropy = sum(
                meta.get('entropy', 0.0) 
                for meta in self.key_metadata.values()
                if meta.get('status') == 'available'
            )
            
            avg_entropy = total_entropy / available_keys if available_keys > 0 else 0.0
            
            return {
                'total_keys': len(self.pool),
                'available_keys': available_keys,
                'in_use_keys': in_use_keys,
                'consumed_keys': len(self.used_keys),
                'average_entropy': avg_entropy,
                'pool_health': 'healthy' if available_keys >= self.min_pool_size else 'low',
                'timestamp': datetime.utcnow().isoformat()
            }
    
    async def _maintain_pool(self, kme_service):
        """Background task to maintain minimum pool size"""
        while True:
            try:
                await asyncio.sleep(60)  # Check every minute
                
                status = await self.get_pool_status()
                available = status['available_keys']
                
                if available < self.min_pool_size:
                    # Generate more keys
                    needed = self.min_pool_size - available
                    logger.info(f"Pool low ({available} keys), generating {needed} more...")
                    
                    new_keys = await self._generate_keys_from_kme1(kme_service, needed)
                    
                    async with self.lock:
                        for key_data in new_keys:
                            key_id = key_data['key_id']
                            self.pool[key_id] = key_data['key_bytes']
                            self.key_metadata[key_id] = {
                                'generated_at': datetime.utcnow(),
                                'source': 'KME1',
                                'size': len(key_data['key_bytes']),
                                'entropy': key_data.get('entropy', 0.0),
                                'status': 'available',
                                'algorithm': key_data.get('algorithm', 'QUANTUM_OTP')
                            }
                    
                    logger.info(f"Added {len(new_keys)} keys to pool")
                
                # Clean up old consumed keys from metadata
                async with self.lock:
                    cutoff = datetime.utcnow() - timedelta(hours=24)
                    old_keys = [
                        kid for kid, meta in self.key_metadata.items()
                        if (meta.get('status') == 'consumed' and 
                            meta.get('consumed_at', datetime.utcnow()) < cutoff)
                    ]
                    
                    for kid in old_keys:
                        del self.key_metadata[kid]
                        self.used_keys.discard(kid)
                    
                    if old_keys:
                        logger.info(f"Cleaned up {len(old_keys)} old consumed keys")
                
            except Exception as e:
                logger.error(f"Error in pool maintenance: {e}")
                await asyncio.sleep(60)

# Global quantum key pool instance
quantum_key_pool = QuantumKeyPool()
